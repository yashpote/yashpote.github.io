<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rahul Gupta on Rahul Gupta</title>
    <link>https://rahulguptakota.github.io/</link>
    <description>Recent content in Rahul Gupta on Rahul Gupta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <copyright>&amp;copy; 2017 Rahul Gupta</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>WAPS: Weighted and Projected Sampling</title>
      <link>https://rahulguptakota.github.io/post/waps/</link>
      <pubDate>Fri, 03 May 2019 11:06:17 +0530</pubDate>
      
      <guid>https://rahulguptakota.github.io/post/waps/</guid>
      <description>&lt;p&gt;This blogpost talks about our tool &lt;a href=&#34;https://github.com/meelgroup/WAPS&#34; target=&#34;_blank&#34;&gt;WAPS&lt;/a&gt;. Specifically, we will talk about how we are able to utilize the idea of sampling using knowledge compilations (d-DNNFs) from our previous work (&lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/Papers/lpar18.pdf&#34; target=&#34;_blank&#34;&gt;KUS&lt;/a&gt;) and generalize it in order to achieve weighted and projected sampling. This work was jointly performed by &lt;a href=&#34;https://rahulguptakota.github.io/&#34; target=&#34;_blank&#34;&gt;Rahul&lt;/a&gt; and &lt;a href=&#34;https://smsharma1.github.io/&#34; target=&#34;_blank&#34;&gt;Shubham&lt;/a&gt; in the mentorship of &lt;a href=&#34;https://www.cse.iitk.ac.in/users/subhajit/&#34; target=&#34;_blank&#34;&gt;Subhajit&lt;/a&gt; and &lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/&#34; target=&#34;_blank&#34;&gt;Kuldeep&lt;/a&gt;. You can read the paper &lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/Papers/tacas19.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and get the tool &lt;a href=&#34;https://github.com/meelgroup/WAPS&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. You can read the previous &lt;a href=&#34;https://meelgroup.github.io/post/kus/&#34; target=&#34;_blank&#34;&gt;blog&lt;/a&gt; that describes uniform sampling using knowledge compilations, though it is not absolutely necessary for this post.
&lt;!-- Don&#39;t worry if you haven&#39;t read the previous blog, I am going to mention the required details here.  --&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s talk about what it means to achieve weighted sampling at first.
&lt;h3&gt;Weighted Sampling&lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Given a formula $F$ and a weight function $W$, the objective of $weighted$ sampling is to draw samples from the set of satisfying assignments of $F$ called $R_{F}$ using a generator $\mathcal{G}^{w}(F, W)$ that ensures
 $$\forall y \in R_{F}, \mathsf{Pr}\left[\mathcal{G}^{w}(F, W) = y\right] = \frac{W(y)}{W(R_F)}$$&lt;/p&gt;

&lt;!-- So, we are trying to construct a weighted probabilistic generator. --&gt;

&lt;p&gt;Intuitively, this just means that the probability of drawing a sample is proportional to its weight. In our case, we are dealing with literal-weighted weight function and the weight of an assignment is simply given by the product of weight of individual literals in the assignment. Broadly speaking, WAPS proceeds in three stages:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;d-DNNF compilation&lt;/li&gt;
&lt;li&gt;Annotation&lt;/li&gt;
&lt;li&gt;Sampling.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s look at what a typical d-DNNF looks like:
&lt;img src=&#34;dDNNFexample.png&#34; alt=&#34;alt_text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;d-DNNF (Deterministic Decomposable Negation Normal Form) can be seen as a compact representation of the satisfying assignments for a given formula. One can also view it as the search space of component decomposition based DPLL procedures popularly employed in SAT solving and model counting. This perspective is helpful for Projected Sampling as you will see. Essentially, in a d-DNNF, the formulae given by children of OR nodes have different (inconsistent to be precise) satisfying assignments (determinism); so, you can choose one of the children if you were to sample a satisfying assignment. On the other hand, the children of AND nodes are drawn over mutually disjoint sets of variables (decomposability);thus allowing you to simply stitch samples drawn from different children to get an overall sample.&lt;/p&gt;

&lt;p&gt;WAPS proceeds by first compiling the given CNF formula into its d-DNNF. This is followed by Annotation. The central idea in WAPS is to annotate the compiled d-DNNF in a way which allows weighted sampling by simply performing weighted bernoulli trials over d-DNNF in the Sampling phase (Refer to our &lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/Papers/tacas19.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; for more details).
The weight annotation is summarised by the figures below:&lt;/p&gt;

&lt;div class=&#34;row&#34;&gt;
  &lt;div class=&#34;col-sm-5&#34;&gt;
    &lt;img src=&#34;WAnnotate.png&#34; alt=&#34;Snow&#34; class=&#34;center&#34;&gt;
  &lt;/div&gt;
  &lt;div class=&#34;col-sm-7&#34;&gt;
    &lt;img src=&#34;WAnnotate2.png&#34; alt=&#34;Forest&#34; class=&#34;center&#34;&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In our paper, we show that this annotation scheme allows you to perform weighted sampling.&lt;/p&gt;

&lt;p&gt;&lt;h3&gt; Weighted and Projected Sampling &lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Given a formula $F$, a set of projecting variables $P$ and a weight function $W$, the objective of $weighted~and~projected$ sampling is to draw samples from the set of satisfying assignments of $F$ projected over $P$ called $R_{F\downarrow P}$ using a generator $\mathcal{G}^{wp}(F, P, W)$ that ensures
$$\forall y \in R_{F\downarrow P}, \mathsf{Pr}\left[\mathcal{G}^{wp}(F, P, W) = y\right] = \frac{W(y)}{W(R_{F\downarrow P})}$$
Intuitively, this means that samples drawn contain only a subset of variables ($P$) as opposed to all variables in the formula and these samples obey the weight distribution given by $W$ over the variables appearing in samples. This has applications in hardware verification and other places where encoding original problem into CNF generates additional Tseitin variables while weight distribution is only defined on original variables in the problem. In such cases, we are often interested in samples from variables of the original problem.&lt;/p&gt;

&lt;p&gt;&lt;h4&gt;Projected Sampling &lt;/h4&gt;
To achieve Projected Sampling, we aim to produce a d-DNNF which represents the set of satisfying assignments projected over a given set of projecting variables. To accomplish this, we modified Dsharp, a state of the art d-DNNF compiler to search first on projecting variables and then simply check if the residual formula is satisfiable to retain the corresponding path in d-DNNF. Notably, this technique has been used in the context of Projected Model Counting and Quantitative Information Flow before.&lt;/p&gt;

&lt;p&gt;The above technique combined with weighted sampling sums up the buildup of WAPS (Weighted and Projected Sampler).&lt;/p&gt;

&lt;p&gt;&lt;h4&gt; Incremental Sampling &lt;/h4&gt;
Another interesting property as a side-effect of knowledge compilation based sampling is that incremental sampling (i.e. fetching multiple relatively short sized samples) can be performed efficiently. This is simply done by saving the compiled d-DNNF or its annotated version depending upon whether weights change in different iterations.&lt;/p&gt;

&lt;p&gt;&lt;h3&gt; Results &lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Our experiments demonstrate that WAPS is able to significantly outperform existing state-of-the-art weighted and projected sampler WeightGen, by up to $3$ orders of magnitude in terms of runtime while
achieving a geometric speedup of $296\times$. For $incremental~sampling$ i.e. fetching multiple, relatively small-sized samples, repeatedly, WAPS achieves a geometric speedup of $3.69$. Also, WAPS is almost oblivious to the number of samples requested. Empirically, the distribution generated by WAPS is statistically indistinguishable from that generated by an ideal weighted and projected sampler.  Also, while performing conditioned sampling in WAPS, we incur no extra cost in terms of runtime in most of the cases. Moreover, the performance of our knowledge compilation based sampling technique is found to be oblivious to weight distribution. Detailed data is available at &lt;a href=&#34;https://github.com/meelgroup/waps&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;h3&gt; Final Thoughts &lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This work has further tapped into the potential of sampling using knowledge compilations by developing procedures that allow weighted and projected sampling. We believe that the general idea of annotating knowledge compilations in different ways has even greater potential for sampling suited to a wider set of applications. Further work can also explore the development of faster sampling methods which leverage partially compiled d-DNNFs. Moreover, comparing the performance as well as functional capabilities with regard to sampling in different knowledge compilations such as SDDs(Sequential Decision Diagrams) is an interesting direction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WAPS: Weighted and Projected Sampling </title>
      <link>https://rahulguptakota.github.io/publication/tacas19/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0530</pubDate>
      
      <guid>https://rahulguptakota.github.io/publication/tacas19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Verity: Blockchains to Detect Insider Attacks in DBMS</title>
      <link>https://rahulguptakota.github.io/publication/verity/</link>
      <pubDate>Wed, 02 Jan 2019 14:45:30 +0530</pubDate>
      
      <guid>https://rahulguptakota.github.io/publication/verity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Knowledge Compilation meets Uniform Sampling</title>
      <link>https://rahulguptakota.github.io/publication/lpar18/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0530</pubDate>
      
      <guid>https://rahulguptakota.github.io/publication/lpar18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Detecting Insider Attacks on Databases using Blockchains</title>
      <link>https://rahulguptakota.github.io/publication/isrdc17/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://rahulguptakota.github.io/publication/isrdc17/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://rahulguptakota.github.io/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0530</pubDate>
      
      <guid>https://rahulguptakota.github.io/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://rahulguptakota.github.io/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://rahulguptakota.github.io/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://rahulguptakota.github.io/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://rahulguptakota.github.io/project/example-external-project/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
